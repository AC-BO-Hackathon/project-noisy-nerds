{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3263ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install botorch gpytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a718b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b3bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def schwefel_1d(x):\n",
    "\n",
    "    return 418.9829  - x * np.sin(np.sqrt(np.abs(x)))\n",
    "\n",
    "def schwefel_nd(args):\n",
    "    output = 0\n",
    "    \n",
    "    for dim in range(args):\n",
    "        output += schwefel_1d(args[dim])\n",
    "\n",
    "def add_gaussian_noise(signal, noise_level):\n",
    "\n",
    "    return signal + np.random.normal(0, noise_level, 1)[0]\n",
    "\n",
    "def schwefel_1d_with_noise(x, noise_level = 0.01):\n",
    "    # Calculate the Schwefel function value\n",
    "\n",
    "    schwefel_value = schwefel_1d(x)\n",
    "\n",
    "    # Add Gaussian noise to the Schwefel function value\n",
    "\n",
    "    noisy_schwefel_value = add_gaussian_noise(schwefel_value, noise_level)\n",
    "\n",
    "    return noisy_schwefel_value\n",
    "\n",
    "def schwefel_nd_with_noise(args, noise_level = 0.01):\n",
    "    # Calculate the Schwefel function value\n",
    "\n",
    "    schwefel_value = schwefel_nd(args)\n",
    "\n",
    "    # Add Gaussian noise to the Schwefel function value\n",
    "\n",
    "    noisy_schwefel_value = add_gaussian_noise(schwefel_value, noise_level)\n",
    "\n",
    "    return noisy_schwefel_value\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4f9bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_data(seed, n_init, noise_level):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    X_bounds = np.array([-500,  500])\n",
    "    X = np.random.uniform(X_bounds[0], X_bounds[1], size=( n_init,))\n",
    "    X = np.append(X, X_bounds)\n",
    "    X = np.sort(X)\n",
    "    y = schwefel_1d_with_noise(X, noise_level = noise_level)\n",
    "\n",
    "    X_unmeasured = np.linspace(X_bounds[0], X_bounds[1], 200)\n",
    "    ground_truth = schwefel_1d_with_noise(X_unmeasured, noise_level = 0)\n",
    "    \n",
    "    return X.reshape(-1,1), y.reshape(-1,1), X_unmeasured.reshape(-1,1), ground_truth.reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6500496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "import gpytorch\n",
    "\n",
    "def step(X_measured, y_measured, X_unmeasured):\n",
    "    # Convert data to tensors\n",
    "    \n",
    "    \n",
    "    # Initialize GP model\n",
    "#     print(X_measured.shape, y_measured.unsqueeze(-1).shape)\n",
    "    gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
    "    \n",
    "    # Fit GP model\n",
    "    mll = ExactMarginalLogLikelihood(gp_model.likelihood, gp_model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    \n",
    "    # Predict on unmeasured data\n",
    "    gp_model.eval()\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        posterior = gp_model(torch.tensor(X_unmeasured))\n",
    "        # For visualization or further processing, you can obtain mean and variance\n",
    "        y_pred = posterior.mean\n",
    "        y_sampled = posterior.variance.sqrt()\n",
    "    \n",
    "    # Compute acquisition function (Expected Improvement here)\n",
    "    EI = ExpectedImprovement(model=gp_model, best_f=y_measured.max(), maximize=True)\n",
    "    acq_values = EI(X_unmeasured.unsqueeze(-2))\n",
    "    \n",
    "    return acq_values, (y_pred, y_sampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2653595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def run_gp(num_steps, X, y, X_unmeasured, ground_truth, schwefel_1d_with_noise, noise_level):\n",
    "#     X = torch.tensor(X)\n",
    "#     y = torch.tensor(y)\n",
    "#     X_unmeasured = torch.tensor(X_unmeasured)\n",
    "#     ground_truth = torch.tensor(ground_truth)\n",
    "    \n",
    "#     for e in range(num_steps):\n",
    "#         print(f\"\\nStep {e+1}/{num_steps}\")\n",
    "#         # Compute acquisition function and get predictions\n",
    "#         acq, (y_pred, y_sampled) = step(X, y, X_unmeasured)\n",
    "        \n",
    "#         # Get the next point to evaluate\n",
    "#         idx = acq.argmax()  # Use argmax since EI maximizes the acquisition\n",
    "#         next_point = X_unmeasured[idx]\n",
    "        \n",
    "#         # Measure the point\n",
    "#         next_point_value = schwefel_1d_with_noise(next_point.numpy(), noise_level)\n",
    "        \n",
    "#         # Update measured data\n",
    "#         X = torch.cat([X, next_point.unsqueeze(0)], dim=0)\n",
    "#         y = torch.cat([y, torch.tensor([next_point_value], dtype=torch.float)], dim=0)\n",
    "    \n",
    "#     # Calculate metrics after the loop\n",
    "#     mse = torch.mean((y_pred - ground_truth) ** 2).item()\n",
    "#     average_uncertainty = torch.mean(y_sampled).item()\n",
    "    \n",
    "#     return mse, average_uncertainty\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def standardize_data(data):\n",
    "    \"\"\"Standardize data to have mean=0 and std=1.\"\"\"\n",
    "    mean = torch.mean(data, dim=0, keepdim=True)\n",
    "    std = torch.std(data, dim=0, keepdim=True)\n",
    "    return (data - mean) / std\n",
    "\n",
    "\n",
    "def run_gp(num_steps, X, y, X_unmeasured, ground_truth, schwefel_1d_with_noise, noise_level):\n",
    "    # Convert to tensors and standardize\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    X_unmeasured = torch.tensor(X_unmeasured, dtype=torch.float32)\n",
    "    ground_truth = torch.tensor(ground_truth, dtype=torch.float32)\n",
    "    \n",
    "    # Standardize features and target\n",
    "    X = standardize_data(X)\n",
    "    X_unmeasured = standardize_data(X_unmeasured)\n",
    "    y= standardize_data(y)\n",
    "    ground_truth = standardize_data(ground_truth)\n",
    "    for e in range(num_steps):\n",
    "        print(f\"\\nStep {e+1}/{num_steps}\")\n",
    "        # Compute acquisition function and get predictions\n",
    "        acq, (y_pred, y_sampled) = step(X, y, X_unmeasured)\n",
    "        \n",
    "        # Rest of your loop...\n",
    "\n",
    "    # Calculate metrics after the loop\n",
    "    mse = torch.mean((y_pred - ground_truth) ** 2).item()\n",
    "    average_uncertainty = torch.mean(y_sampled).item()\n",
    "    \n",
    "    return mse, average_uncertainty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6205bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "def grid_search(seeds, n_inits, noise_levels):\n",
    "    results = []  # Initialize an empty list to store results\n",
    "\n",
    "    # Iterate over all combinations of seeds, n_inits, and noise_levels\n",
    "    for seed, n_init, noise_level in itertools.product(seeds, n_inits, noise_levels):\n",
    "        print(f\"Seed: {seed}, n_init: {n_init}, Noise Level: {noise_level}\")\n",
    "        \n",
    "        # Create data for the current combination\n",
    "        X, y, X_unmeasured, ground_truth = create_data(seed, n_init, noise_level)\n",
    "        print(X.shape)  # Should be [n, d] where d is the number of dimensions/features\n",
    "        print(y.shape) \n",
    "        # Run Gaussian Process (GP) optimization/modeling for the current combination\n",
    "        mse, average_uncertainty = run_gp(5, X, y, X_unmeasured, ground_truth, schwefel_1d_with_noise, noise_level)\n",
    "        print(mse)\n",
    "        # Collect the results\n",
    "        results.append({\n",
    "            \"Seed\": seed,\n",
    "            \"n_init\": n_init,\n",
    "            \"Noise_Level\": noise_level,\n",
    "            \"MSE\": mse,\n",
    "            \"Average_Uncertainty\": average_uncertainty\n",
    "        })\n",
    "\n",
    "    # Convert the results to a pandas DataFrame for easy analysis and reporting\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8f5ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "01f42404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 1, n_init: 5, Noise Level: 0\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4834703207015991\n",
      "Seed: 1, n_init: 5, Noise Level: 0.01\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.471142292022705\n",
      "Seed: 1, n_init: 5, Noise Level: 0.1\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4834703207015991\n",
      "Seed: 1, n_init: 5, Noise Level: 0.5\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.490060567855835\n",
      "Seed: 1, n_init: 10, Noise Level: 0\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4958250522613525\n",
      "Seed: 1, n_init: 10, Noise Level: 0.01\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4987499713897705\n",
      "Seed: 1, n_init: 10, Noise Level: 0.1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4684855937957764\n",
      "Seed: 1, n_init: 10, Noise Level: 0.5\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.4980649948120117\n",
      "Seed: 1, n_init: 15, Noise Level: 0\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0959746837615967\n",
      "Seed: 1, n_init: 15, Noise Level: 0.01\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8582366704940796\n",
      "Seed: 1, n_init: 15, Noise Level: 0.1\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/gpytorch/distributions/multivariate_normal.py:319: NumericalWarning: Negative variance values detected. This is likely due to numerical instabilities. Rounding negative variances up to 1e-06.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/optim/fit.py:102: OptimizationWarning: `scipy_minimize` terminated with status 3, displaying original message from `scipy.optimize.minimize`: ABNORMAL_TERMINATION_IN_LNSRCH\n",
      "  warn(\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8659234046936035\n",
      "Seed: 1, n_init: 15, Noise Level: 0.5\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.850039005279541\n",
      "Seed: 1, n_init: 20, Noise Level: 0\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.9220656156539917\n",
      "Seed: 1, n_init: 20, Noise Level: 0.01\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n",
      "1.7824245691299438\n",
      "Seed: 1, n_init: 20, Noise Level: 0.1\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.952939510345459\n",
      "Seed: 1, n_init: 20, Noise Level: 0.5\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.9188467264175415\n",
      "Seed: 1, n_init: 25, Noise Level: 0\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "2.348071575164795\n",
      "Seed: 1, n_init: 25, Noise Level: 0.01\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "2.3391432762145996\n",
      "Seed: 1, n_init: 25, Noise Level: 0.1\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3390276432037354\n",
      "Seed: 1, n_init: 25, Noise Level: 0.5\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3398637771606445\n",
      "Seed: 2, n_init: 5, Noise Level: 0\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0889959335327148\n",
      "Seed: 2, n_init: 5, Noise Level: 0.01\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0889965295791626\n",
      "Seed: 2, n_init: 5, Noise Level: 0.1\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.0889968872070312\n",
      "Seed: 2, n_init: 5, Noise Level: 0.5\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0889971256256104\n",
      "Seed: 2, n_init: 10, Noise Level: 0\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.6680113077163696\n",
      "Seed: 2, n_init: 10, Noise Level: 0.01\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.6696722507476807\n",
      "Seed: 2, n_init: 10, Noise Level: 0.1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.6700429916381836\n",
      "Seed: 2, n_init: 10, Noise Level: 0.5\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6719379425048828\n",
      "Seed: 2, n_init: 15, Noise Level: 0\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.7897077798843384\n",
      "Seed: 2, n_init: 15, Noise Level: 0.01\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7927340269088745\n",
      "Seed: 2, n_init: 15, Noise Level: 0.1\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.7925740480422974\n",
      "Seed: 2, n_init: 15, Noise Level: 0.5\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7896960973739624\n",
      "Seed: 2, n_init: 20, Noise Level: 0\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n",
      "2.1042706966400146\n",
      "Seed: 2, n_init: 20, Noise Level: 0.01\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.103878974914551\n",
      "Seed: 2, n_init: 20, Noise Level: 0.1\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n",
      "2.104372262954712\n",
      "Seed: 2, n_init: 20, Noise Level: 0.5\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.103878974914551\n",
      "Seed: 2, n_init: 25, Noise Level: 0\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1595683097839355\n",
      "Seed: 2, n_init: 25, Noise Level: 0.01\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "2.1565327644348145\n",
      "Seed: 2, n_init: 25, Noise Level: 0.1\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.161508798599243\n",
      "Seed: 2, n_init: 25, Noise Level: 0.5\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.159533977508545\n",
      "Seed: 3, n_init: 5, Noise Level: 0\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6003402471542358\n",
      "Seed: 3, n_init: 5, Noise Level: 0.01\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.60093355178833\n",
      "Seed: 3, n_init: 5, Noise Level: 0.1\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6003402471542358\n",
      "Seed: 3, n_init: 5, Noise Level: 0.5\n",
      "(7, 1)\n",
      "(7, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6003451347351074\n",
      "Seed: 3, n_init: 10, Noise Level: 0\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.451256275177002\n",
      "Seed: 3, n_init: 10, Noise Level: 0.01\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.4498707056045532\n",
      "Seed: 3, n_init: 10, Noise Level: 0.1\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4499812126159668\n",
      "Seed: 3, n_init: 10, Noise Level: 0.5\n",
      "(12, 1)\n",
      "(12, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.449458360671997\n",
      "Seed: 3, n_init: 15, Noise Level: 0\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7906279563903809\n",
      "Seed: 3, n_init: 15, Noise Level: 0.01\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "1.7892225980758667\n",
      "Seed: 3, n_init: 15, Noise Level: 0.1\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7892377376556396\n",
      "Seed: 3, n_init: 15, Noise Level: 0.5\n",
      "(17, 1)\n",
      "(17, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.789238691329956\n",
      "Seed: 3, n_init: 20, Noise Level: 0\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "2.0686287879943848\n",
      "Seed: 3, n_init: 20, Noise Level: 0.01\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.053746223449707\n",
      "Seed: 3, n_init: 20, Noise Level: 0.1\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0540030002593994\n",
      "Seed: 3, n_init: 20, Noise Level: 0.5\n",
      "(22, 1)\n",
      "(22, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0544493198394775\n",
      "Seed: 3, n_init: 25, Noise Level: 0\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n",
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "2.0695652961730957\n",
      "Seed: 3, n_init: 25, Noise Level: 0.01\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5/5\n",
      "2.0689313411712646\n",
      "Seed: 3, n_init: 25, Noise Level: 0.1\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0327603816986084\n",
      "Seed: 3, n_init: 25, Noise Level: 0.5\n",
      "(27, 1)\n",
      "(27, 1)\n",
      "\n",
      "Step 1/5\n",
      "\n",
      "Step 2/5\n",
      "\n",
      "Step 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n",
      "/tmp/ipykernel_1292286/1166517645.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gp_model = SingleTaskGP(torch.tensor(X_measured), torch.tensor(y_measured))\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/gp_regression.py:161: UserWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  self._validate_tensor_args(X=transformed_X, Y=train_Y, Yvar=train_Yvar)\n",
      "/nfs/home/upratius/.conda/envs/gpax_hae/lib/python3.10/site-packages/botorch/models/utils/assorted.py:174: InputDataWarning: Input data is not contained to the unit cube. Please consider min-max scaling the input data.\n",
      "  warnings.warn(msg, InputDataWarning)\n",
      "/tmp/ipykernel_1292286/1166517645.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  posterior = gp_model(torch.tensor(X_unmeasured))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4/5\n",
      "\n",
      "Step 5/5\n",
      "2.0699245929718018\n",
      "    Seed  n_init  Noise_Level       MSE  Average_Uncertainty\n",
      "0      1       5         0.00  1.483470             0.533026\n",
      "1      1       5         0.01  1.471142             0.559593\n",
      "2      1       5         0.10  1.483470             0.533026\n",
      "3      1       5         0.50  1.490061             0.552982\n",
      "4      1      10         0.00  1.495825             0.691920\n",
      "5      1      10         0.01  1.498750             0.697778\n",
      "6      1      10         0.10  1.468486             0.678819\n",
      "7      1      10         0.50  1.498065             0.701203\n",
      "8      1      15         0.00  3.095975             0.546266\n",
      "9      1      15         0.01  1.858237             0.474034\n",
      "10     1      15         0.10  1.865923             0.469591\n",
      "11     1      15         0.50  1.850039             0.471573\n",
      "12     1      20         0.00  1.922066             0.307850\n",
      "13     1      20         0.01  1.782425             0.365753\n",
      "14     1      20         0.10  1.952940             0.362849\n",
      "15     1      20         0.50  1.918847             0.308808\n",
      "16     1      25         0.00  2.348072             0.225434\n",
      "17     1      25         0.01  2.339143             0.226166\n",
      "18     1      25         0.10  2.339028             0.225726\n",
      "19     1      25         0.50  2.339864             0.225640\n",
      "20     2       5         0.00  1.088996             0.848628\n",
      "21     2       5         0.01  1.088997             0.848630\n",
      "22     2       5         0.10  1.088997             0.848629\n",
      "23     2       5         0.50  1.088997             0.848631\n",
      "24     2      10         0.00  1.668011             0.796792\n",
      "25     2      10         0.01  1.669672             0.797943\n",
      "26     2      10         0.10  1.670043             0.798097\n",
      "27     2      10         0.50  1.671938             0.800202\n",
      "28     2      15         0.00  1.789708             0.501271\n",
      "29     2      15         0.01  1.792734             0.501560\n",
      "30     2      15         0.10  1.792574             0.501509\n",
      "31     2      15         0.50  1.789696             0.501207\n",
      "32     2      20         0.00  2.104271             0.313216\n",
      "33     2      20         0.01  2.103879             0.313138\n",
      "34     2      20         0.10  2.104372             0.313260\n",
      "35     2      20         0.50  2.103879             0.313138\n",
      "36     2      25         0.00  2.159568             0.236000\n",
      "37     2      25         0.01  2.156533             0.235369\n",
      "38     2      25         0.10  2.161509             0.236499\n",
      "39     2      25         0.50  2.159534             0.236013\n",
      "40     3       5         0.00  1.600340             0.669741\n",
      "41     3       5         0.01  1.600934             0.669584\n",
      "42     3       5         0.10  1.600340             0.669741\n",
      "43     3       5         0.50  1.600345             0.669737\n",
      "44     3      10         0.00  1.451256             0.629858\n",
      "45     3      10         0.01  1.449871             0.631171\n",
      "46     3      10         0.10  1.449981             0.631360\n",
      "47     3      10         0.50  1.449458             0.631218\n",
      "48     3      15         0.00  1.790628             0.425344\n",
      "49     3      15         0.01  1.789223             0.425260\n",
      "50     3      15         0.10  1.789238             0.425436\n",
      "51     3      15         0.50  1.789239             0.425482\n",
      "52     3      20         0.00  2.068629             0.345784\n",
      "53     3      20         0.01  2.053746             0.344664\n",
      "54     3      20         0.10  2.054003             0.344776\n",
      "55     3      20         0.50  2.054449             0.344390\n",
      "56     3      25         0.00  2.069565             0.221183\n",
      "57     3      25         0.01  2.068931             0.221628\n",
      "58     3      25         0.10  2.032760             0.257487\n",
      "59     3      25         0.50  2.069925             0.221043\n"
     ]
    }
   ],
   "source": [
    "# Define your parameter space\n",
    "seeds = [1, 2, 3]\n",
    "n_inits = [5, 10, 15, 20, 25]\n",
    "noise_levels = [0, 0.01, 0.1, 0.5]\n",
    "\n",
    "# Assuming create_data and run_gp functions are defined elsewhere\n",
    "\n",
    "# Run the grid search\n",
    "results_df = grid_search(seeds, n_inits, noise_levels)\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "44006b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('grid_search_results_botorch_v3_normalized.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "af6ce5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>n_init</th>\n",
       "      <th>Noise_Level</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Average_Uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.483470</td>\n",
       "      <td>0.533026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.471142</td>\n",
       "      <td>0.559593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.483470</td>\n",
       "      <td>0.533026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.490061</td>\n",
       "      <td>0.552982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.495825</td>\n",
       "      <td>0.691920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.498750</td>\n",
       "      <td>0.697778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.468486</td>\n",
       "      <td>0.678819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.498065</td>\n",
       "      <td>0.701203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.095975</td>\n",
       "      <td>0.546266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.858237</td>\n",
       "      <td>0.474034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.865923</td>\n",
       "      <td>0.469591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.850039</td>\n",
       "      <td>0.471573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.922066</td>\n",
       "      <td>0.307850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.782425</td>\n",
       "      <td>0.365753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.952940</td>\n",
       "      <td>0.362849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.918847</td>\n",
       "      <td>0.308808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.348072</td>\n",
       "      <td>0.225434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.339143</td>\n",
       "      <td>0.226166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.339028</td>\n",
       "      <td>0.225726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.339864</td>\n",
       "      <td>0.225640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.088996</td>\n",
       "      <td>0.848628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.088997</td>\n",
       "      <td>0.848630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.088997</td>\n",
       "      <td>0.848629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.088997</td>\n",
       "      <td>0.848631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.668011</td>\n",
       "      <td>0.796792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.669672</td>\n",
       "      <td>0.797943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.670043</td>\n",
       "      <td>0.798097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.671938</td>\n",
       "      <td>0.800202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.789708</td>\n",
       "      <td>0.501271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.792734</td>\n",
       "      <td>0.501560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.792574</td>\n",
       "      <td>0.501509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.789696</td>\n",
       "      <td>0.501207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.104271</td>\n",
       "      <td>0.313216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.103879</td>\n",
       "      <td>0.313138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.104372</td>\n",
       "      <td>0.313260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.103879</td>\n",
       "      <td>0.313138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.159568</td>\n",
       "      <td>0.236000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.156533</td>\n",
       "      <td>0.235369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.161509</td>\n",
       "      <td>0.236499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.159534</td>\n",
       "      <td>0.236013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.600340</td>\n",
       "      <td>0.669741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.600934</td>\n",
       "      <td>0.669584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.600340</td>\n",
       "      <td>0.669741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.600345</td>\n",
       "      <td>0.669737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.451256</td>\n",
       "      <td>0.629858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.449871</td>\n",
       "      <td>0.631171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.449981</td>\n",
       "      <td>0.631360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.449458</td>\n",
       "      <td>0.631218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.790628</td>\n",
       "      <td>0.425344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.789223</td>\n",
       "      <td>0.425260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.789238</td>\n",
       "      <td>0.425436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.789239</td>\n",
       "      <td>0.425482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.068629</td>\n",
       "      <td>0.345784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.053746</td>\n",
       "      <td>0.344664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.054003</td>\n",
       "      <td>0.344776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.054449</td>\n",
       "      <td>0.344390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.069565</td>\n",
       "      <td>0.221183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.068931</td>\n",
       "      <td>0.221628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.032760</td>\n",
       "      <td>0.257487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.069925</td>\n",
       "      <td>0.221043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Seed  n_init  Noise_Level       MSE  Average_Uncertainty\n",
       "0      1       5         0.00  1.483470             0.533026\n",
       "1      1       5         0.01  1.471142             0.559593\n",
       "2      1       5         0.10  1.483470             0.533026\n",
       "3      1       5         0.50  1.490061             0.552982\n",
       "4      1      10         0.00  1.495825             0.691920\n",
       "5      1      10         0.01  1.498750             0.697778\n",
       "6      1      10         0.10  1.468486             0.678819\n",
       "7      1      10         0.50  1.498065             0.701203\n",
       "8      1      15         0.00  3.095975             0.546266\n",
       "9      1      15         0.01  1.858237             0.474034\n",
       "10     1      15         0.10  1.865923             0.469591\n",
       "11     1      15         0.50  1.850039             0.471573\n",
       "12     1      20         0.00  1.922066             0.307850\n",
       "13     1      20         0.01  1.782425             0.365753\n",
       "14     1      20         0.10  1.952940             0.362849\n",
       "15     1      20         0.50  1.918847             0.308808\n",
       "16     1      25         0.00  2.348072             0.225434\n",
       "17     1      25         0.01  2.339143             0.226166\n",
       "18     1      25         0.10  2.339028             0.225726\n",
       "19     1      25         0.50  2.339864             0.225640\n",
       "20     2       5         0.00  1.088996             0.848628\n",
       "21     2       5         0.01  1.088997             0.848630\n",
       "22     2       5         0.10  1.088997             0.848629\n",
       "23     2       5         0.50  1.088997             0.848631\n",
       "24     2      10         0.00  1.668011             0.796792\n",
       "25     2      10         0.01  1.669672             0.797943\n",
       "26     2      10         0.10  1.670043             0.798097\n",
       "27     2      10         0.50  1.671938             0.800202\n",
       "28     2      15         0.00  1.789708             0.501271\n",
       "29     2      15         0.01  1.792734             0.501560\n",
       "30     2      15         0.10  1.792574             0.501509\n",
       "31     2      15         0.50  1.789696             0.501207\n",
       "32     2      20         0.00  2.104271             0.313216\n",
       "33     2      20         0.01  2.103879             0.313138\n",
       "34     2      20         0.10  2.104372             0.313260\n",
       "35     2      20         0.50  2.103879             0.313138\n",
       "36     2      25         0.00  2.159568             0.236000\n",
       "37     2      25         0.01  2.156533             0.235369\n",
       "38     2      25         0.10  2.161509             0.236499\n",
       "39     2      25         0.50  2.159534             0.236013\n",
       "40     3       5         0.00  1.600340             0.669741\n",
       "41     3       5         0.01  1.600934             0.669584\n",
       "42     3       5         0.10  1.600340             0.669741\n",
       "43     3       5         0.50  1.600345             0.669737\n",
       "44     3      10         0.00  1.451256             0.629858\n",
       "45     3      10         0.01  1.449871             0.631171\n",
       "46     3      10         0.10  1.449981             0.631360\n",
       "47     3      10         0.50  1.449458             0.631218\n",
       "48     3      15         0.00  1.790628             0.425344\n",
       "49     3      15         0.01  1.789223             0.425260\n",
       "50     3      15         0.10  1.789238             0.425436\n",
       "51     3      15         0.50  1.789239             0.425482\n",
       "52     3      20         0.00  2.068629             0.345784\n",
       "53     3      20         0.01  2.053746             0.344664\n",
       "54     3      20         0.10  2.054003             0.344776\n",
       "55     3      20         0.50  2.054449             0.344390\n",
       "56     3      25         0.00  2.069565             0.221183\n",
       "57     3      25         0.01  2.068931             0.221628\n",
       "58     3      25         0.10  2.032760             0.257487\n",
       "59     3      25         0.50  2.069925             0.221043"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ae8d2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>n_init</th>\n",
       "      <th>Noise_Level</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Average_Uncertainty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42108.119088</td>\n",
       "      <td>17.544797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40813.529530</td>\n",
       "      <td>15.307410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>37841.945077</td>\n",
       "      <td>15.802484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>37550.871366</td>\n",
       "      <td>3.830761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38389.632000</td>\n",
       "      <td>14.470949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>38349.540837</td>\n",
       "      <td>12.016277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>37489.492780</td>\n",
       "      <td>11.868182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>38289.508883</td>\n",
       "      <td>3.746136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40191.983264</td>\n",
       "      <td>3.811547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>37858.782132</td>\n",
       "      <td>22.654309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>37773.534062</td>\n",
       "      <td>17.449285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>40106.162783</td>\n",
       "      <td>20.949178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40301.273881</td>\n",
       "      <td>19.379407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40308.008804</td>\n",
       "      <td>19.379004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>38778.941866</td>\n",
       "      <td>10.257270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>38225.941709</td>\n",
       "      <td>4.929497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38749.761702</td>\n",
       "      <td>4.129729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>38660.032543</td>\n",
       "      <td>14.906107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>37840.004933</td>\n",
       "      <td>4.291684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>37846.269125</td>\n",
       "      <td>4.292110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42369.545363</td>\n",
       "      <td>19.049765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>40294.001498</td>\n",
       "      <td>17.056114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>39115.475050</td>\n",
       "      <td>10.273374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>45580.410145</td>\n",
       "      <td>18.010720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>40642.425485</td>\n",
       "      <td>6.167951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>39174.924580</td>\n",
       "      <td>14.297714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>37548.821345</td>\n",
       "      <td>15.840703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>37905.882849</td>\n",
       "      <td>3.912628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37822.923411</td>\n",
       "      <td>3.523961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>43567.768930</td>\n",
       "      <td>16.288372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>38178.293287</td>\n",
       "      <td>23.374256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>41235.754444</td>\n",
       "      <td>7.550453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>37889.521772</td>\n",
       "      <td>23.649989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>39445.484274</td>\n",
       "      <td>14.958631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>44042.980326</td>\n",
       "      <td>18.591112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>39537.842423</td>\n",
       "      <td>4.317835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Seed  n_init  Noise_Level           MSE  Average_Uncertainty\n",
       "0      1      10         0.00  42108.119088            17.544797\n",
       "1      1      10         0.01  40813.529530            15.307410\n",
       "2      1      10         0.10  37841.945077            15.802484\n",
       "3      1      10         0.50  37550.871366             3.830761\n",
       "4      1      15         0.00  38389.632000            14.470949\n",
       "5      1      15         0.01  38349.540837            12.016277\n",
       "6      1      15         0.10  37489.492780            11.868182\n",
       "7      1      15         0.50  38289.508883             3.746136\n",
       "8      1      20         0.00  40191.983264             3.811547\n",
       "9      1      20         0.01  37858.782132            22.654309\n",
       "10     1      20         0.10  37773.534062            17.449285\n",
       "11     1      20         0.50  40106.162783            20.949178\n",
       "12     2      10         0.00  40301.273881            19.379407\n",
       "13     2      10         0.01  40308.008804            19.379004\n",
       "14     2      10         0.10  38778.941866            10.257270\n",
       "15     2      10         0.50  38225.941709             4.929497\n",
       "16     2      15         0.00  38749.761702             4.129729\n",
       "17     2      15         0.01  38660.032543            14.906107\n",
       "18     2      15         0.10  37840.004933             4.291684\n",
       "19     2      15         0.50  37846.269125             4.292110\n",
       "20     2      20         0.00  42369.545363            19.049765\n",
       "21     2      20         0.01  40294.001498            17.056114\n",
       "22     2      20         0.10  39115.475050            10.273374\n",
       "23     2      20         0.50  45580.410145            18.010720\n",
       "24     3      10         0.00  40642.425485             6.167951\n",
       "25     3      10         0.01  39174.924580            14.297714\n",
       "26     3      10         0.10  37548.821345            15.840703\n",
       "27     3      10         0.50  37905.882849             3.912628\n",
       "28     3      15         0.00  37822.923411             3.523961\n",
       "29     3      15         0.01  43567.768930            16.288372\n",
       "30     3      15         0.10  38178.293287            23.374256\n",
       "31     3      15         0.50  41235.754444             7.550453\n",
       "32     3      20         0.00  37889.521772            23.649989\n",
       "33     3      20         0.01  39445.484274            14.958631\n",
       "34     3      20         0.10  44042.980326            18.591112\n",
       "35     3      20         0.50  39537.842423             4.317835"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "610cd775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame for easier manipulation\n",
    "df = results_df\n",
    "\n",
    "# Plot settings\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot 1: MSE\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first plot\n",
    "for key, grp in df.groupby(['Seed', 'n_init']):\n",
    "    plt.plot(grp['Noise_Level'], grp['MSE'], marker='o', linestyle='-', label=f'Seed {key[0]}, n_init {key[1]}')\n",
    "plt.title('MSE vs. Noise Level')\n",
    "plt.xlabel('Noise Level')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot 2: Average Uncertainty\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second plot\n",
    "for key, grp in df.groupby(['Seed', 'n_init']):\n",
    "    plt.plot(grp['Noise_Level'], grp['Average_Uncertainty'], marker='x', linestyle='--', label=f'Seed {key[0]}, n_init {key[1]}')\n",
    "plt.title('Average Uncertainty vs. Noise Level')\n",
    "plt.xlabel('Noise Level')\n",
    "plt.ylabel('Average Uncertainty')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3efada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-gpax_hae]",
   "language": "python",
   "name": "conda-env-.conda-gpax_hae-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
